# -*- coding: utf-8 -*-
"""
GANè®­ç»ƒå™¨ - æ”¯æŒemojiç¬¦å·å’ŒUnicodeå­—ç¬¦ + DDPåˆ†å¸ƒå¼è®­ç»ƒ
ä½¿ç”¨UTF-8ç¼–ç ç¡®ä¿æ‰€æœ‰å­—ç¬¦æ­£ç¡®æ˜¾ç¤ºå’Œä¿å­˜
æ”¯æŒå•æœºå¤šå¡å’Œå¤šæœºå¤šå¡çš„åˆ†å¸ƒå¼è®­ç»ƒ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel as DDP
import torch.distributed as dist
from torchvision.utils import save_image
import torchvision.utils as vutils
from torch.utils.data import random_split
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import animation
from torch.amp import GradScaler, autocast  # ä½¿ç”¨æ–°çš„API
from IPython.display import HTML
import os
import time
import logging
import logging.config
import argparse

def setup_utf8_environment():
    """è®¾ç½®UTF-8ç¯å¢ƒï¼Œç¡®ä¿emojiç¬¦å·èƒ½æ­£ç¡®æ˜¾ç¤º"""
    import sys
    
    # ä¸ºWindowsè®¾ç½®UTF-8ç¯å¢ƒ
    if os.name == 'nt':  # Windowsç³»ç»Ÿ
        try:
            # è®¾ç½®æ§åˆ¶å°ä»£ç é¡µä¸ºUTF-8
            os.system('chcp 65001 > nul')
            
            # é‡æ–°é…ç½®æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡º
            if hasattr(sys.stdout, 'reconfigure'):
                sys.stdout.reconfigure(encoding='utf-8', errors='replace')
            if hasattr(sys.stderr, 'reconfigure'):
                sys.stderr.reconfigure(encoding='utf-8', errors='replace')
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•è®¾ç½®UTF-8ç¯å¢ƒ: {e}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONIOENCODING'] = 'utf-8'

def safe_emoji(emoji_text, fallback_text):
    """å®‰å…¨çš„emojiæ˜¾ç¤ºå‡½æ•°ï¼Œåœ¨ä¸æ”¯æŒçš„ç¯å¢ƒä¸­ä½¿ç”¨æ›¿ä»£æ–‡æœ¬"""
    try:
        # æµ‹è¯•æ˜¯å¦èƒ½ç¼–ç emoji
        emoji_text.encode('utf-8')
        return emoji_text
    except UnicodeEncodeError:
        return fallback_text

def setup_distributed():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
        
        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)
        torch.cuda.set_device(local_rank)
        
        return True, rank, world_size, local_rank
    else:
        return False, 0, 1, 0

def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()

def is_main_process():
    """åˆ¤æ–­æ˜¯å¦ä¸ºä¸»è¿›ç¨‹"""
    return not dist.is_initialized() or dist.get_rank() == 0

# åœ¨æ¨¡å—åŠ è½½æ—¶ç«‹å³è®¾ç½®UTF-8ç¯å¢ƒ
setup_utf8_environment()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def collate_fn(batch):
    """æ‰¹é‡æ•°æ®æ•´ç†å‡½æ•°ï¼Œç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ"""
    images, labels = zip(*batch)
    # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ä½¿ç”¨å½“å‰è®¾å¤‡
    if dist.is_initialized():
        device = torch.cuda.current_device()
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    images = torch.stack([img.to(device) for img in images])
    # å°†æ ‡ç­¾è½¬æ¢ä¸ºtensorå¹¶ç§»åŠ¨åˆ°è®¾å¤‡
    labels = torch.tensor(labels, device=device)
    return images, labels

class MyDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.jpg', '.png'))]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.image_files[idx])
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        # è¿”å›tensorç±»å‹çš„æ ‡ç­¾ä»¥ä¿æŒä¸€è‡´æ€§
        return image, torch.tensor(0)

class Generator(nn.Module):
    def __init__(self, latent_dim, num_layers, base_channels):
        super(Generator, self).__init__()
        layers = []
        for i in range(num_layers):
            if i == 0:
                layers.append(nn.ConvTranspose2d(latent_dim, base_channels * 8, 4, 1, 0, bias=False))
            else:
                layers.append(nn.ConvTranspose2d(base_channels * (8 // (2 ** (i - 1))), base_channels * (8 // (2 ** i)), 4, 2, 1, bias=False))
            layers.append(nn.BatchNorm2d(base_channels * (8 // (2 ** i))))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
        layers.append(nn.ConvTranspose2d(base_channels, 3, 4, 2, 1, bias=False))
        layers.append(nn.Tanh())
        self.main = nn.Sequential(*layers)


    def forward(self, input):
        return self.main(input.to(torch.float32))# å°†æƒé‡ç±»å‹è®¾ç½®ä¸ºå•ç²¾åº¦æµ®ç‚¹æ•°

class Discriminator(nn.Module):
    def __init__(self, num_layers, base_channels):
        super(Discriminator, self).__init__()
        layers = []
        for i in range(num_layers):
            if i == 0:
                layers.append(nn.Conv2d(3, base_channels, 4, 2, 1, bias=False))
            else:
                layers.append(nn.Conv2d(base_channels * (2 ** (i - 1)), base_channels * (2 ** i), 4, 2, 1, bias=False))
                layers.append(nn.BatchNorm2d(base_channels * (2 ** i)))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
        layers.append(nn.Conv2d(base_channels * (2 ** (num_layers - 1)), 1, 4, 1, 0, bias=False))
        self.main = nn.Sequential(*layers)

    def forward(self, input):
        return self.main(input.to(torch.float32))

class GANTrainer:
    def __init__(self, dataset_path, latent_dim=100, lr_G=0.0002, lr_D=0.0002, betas=(0.5, 0.999), batch_size=128, image_size=64,
                 epochs=50,start_epoch=0,patience=5, min_delta=0.0001, num_layers=4, base_channels=64, load_models=False,gradient_accumulation_steps=1, validation_frequency=10):
        
        # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ
        self.is_distributed, self.rank, self.world_size, self.local_rank = setup_distributed()
        
        self.dataset_path = dataset_path
        self.latent_dim = latent_dim
        self.lr_G = lr_G
        self.lr_D = lr_D
        self.betas = betas
        self.batch_size = batch_size
        self.image_size = image_size
        self.epochs = epochs
        self.start_epoch=start_epoch
        self.patience = patience
        self.min_delta = min_delta
        self.num_layers = num_layers
        self.base_channels = base_channels
        self.gradient_accumulation_steps = gradient_accumulation_steps
        self.validation_frequency = validation_frequency  # æ–°å¢éªŒè¯é¢‘ç‡å‚æ•°ï¼Œä¸patienceè¯­ä¹‰åˆ†ç¦»
        self.load_models = load_models  # ä¿å­˜åŠ è½½æ¨¡å‹æ ‡å¿—
        self.best_val_loss = float('inf')  # è®¾ç½®ä¸€ä¸ªåˆå§‹å€¼ï¼Œä¾‹å¦‚æ­£æ— ç©·å¤§

        # è®¾ç½®è®¾å¤‡
        if self.is_distributed:
            self.device = torch.device(f'cuda:{self.local_rank}')
            torch.cuda.set_device(self.local_rank)
        else:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # ç»Ÿä¸€Loggerç®¡ç† - åªåœ¨ä¸»è¿›ç¨‹åˆ›å»ºlogger
        if is_main_process():
            self.logger = self._setup_logger()
            self.logger.debug(f'{safe_emoji("ğŸ’»", "[DEVICE]")} å½“å‰ä½¿ç”¨çš„è®¾å¤‡æ˜¯ï¼š{self.device}')
            if self.is_distributed:
                self.logger.info(f'{safe_emoji("ğŸŒ", "[DDP]")} åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼ï¼šRank {self.rank}/{self.world_size}, Local Rank: {self.local_rank}')
        else:
            self.logger = None

        self.generator = Generator(latent_dim, num_layers, base_channels).to(self.device)
        self.discriminator = Discriminator(num_layers, base_channels).to(self.device)

        # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­åŒæ­¥BNå±‚
        if self.is_distributed:
            self.generator = torch.nn.SyncBatchNorm.convert_sync_batchnorm(self.generator)
            self.discriminator = torch.nn.SyncBatchNorm.convert_sync_batchnorm(self.discriminator)

        self.criterion = nn.BCEWithLogitsLoss()
        self.optimizer_G = torch.optim.AdamW(self.generator.parameters(), lr=self.lr_G, betas=betas)
        self.optimizer_D = torch.optim.AdamW(self.discriminator.parameters(), lr=self.lr_D, betas=betas)

        self.scheduler_G = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer_G, T_max=self.epochs)
        self.scheduler_D = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer_D, T_max=self.epochs)

        # ä¸ºDDPè®¾ç½®GradScaler
        if self.is_distributed:
            self.scaler = GradScaler('cuda')
        else:
            self.scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')

        self.dataset = self.load_dataset()
        self.train_dataloader, self.val_dataloader = self.split_dataset()
        
        # åŒ…è£…æ¨¡å‹ä¸ºDDP
        if self.is_distributed:
            self.generator = DDP(self.generator, device_ids=[self.local_rank], output_device=self.local_rank, find_unused_parameters=True)
            self.discriminator = DDP(self.discriminator, device_ids=[self.local_rank], output_device=self.local_rank, find_unused_parameters=True)
        
        plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

        self.train_epoch_dir = 'train_epoch'  # Specify the directory for saving files

        # åªåœ¨ä¸»è¿›ç¨‹åˆ›å»ºç›®å½•
        if is_main_process() and not os.path.exists(self.train_epoch_dir):
            os.makedirs(self.train_epoch_dir)

    def _setup_logger(self):
        """ç»Ÿä¸€è®¾ç½®Loggeré…ç½®"""
        module_name = 'YPS'
        logger = logging.getLogger(f'{__name__}')
        
        # å¦‚æœloggerå·²ç»æœ‰handlerï¼Œå…ˆæ¸…ç©ºé¿å…é‡å¤
        if logger.handlers:
            logger.handlers.clear()
            
        logger.setLevel(logging.DEBUG)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists('train_epoch'):
            os.makedirs('train_epoch')

        # ä½¿ç”¨UTF-8ç¼–ç æ¥æ”¯æŒemojiç¬¦å·
        fh = logging.FileHandler(
            os.path.join('train_epoch', f"{module_name}_è®­ç»ƒlog.txt"), 
            encoding='utf-8'
        )
        fh.setLevel(logging.DEBUG)

        ch = logging.StreamHandler()
        ch.setLevel(logging.DEBUG)

        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        fh.setFormatter(formatter)
        ch.setFormatter(formatter)

        logger.addHandler(fh)
        logger.addHandler(ch)
        
        return logger

    def safe_log(self, level, message):
        """å®‰å…¨çš„æ—¥å¿—è®°å½•æ–¹æ³•ï¼Œåªåœ¨ä¸»è¿›ç¨‹ä¸”loggerå­˜åœ¨æ—¶è®°å½•"""
        if is_main_process() and self.logger:
            getattr(self.logger, level)(message)

    def _load_models_unified(self):
        """ç»Ÿä¸€çš„æ¨¡å‹åŠ è½½æ–¹æ³•ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„åŠ è½½æ–¹å¼ï¼Œæ”¯æŒDDP"""
        if not self.load_models:
            if is_main_process() and self.logger:
                self.logger.debug("æœªå¯ç”¨æ¨¡å‹åŠ è½½ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
            return 0
            
        # ä¼˜å…ˆçº§1: å°è¯•åŠ è½½å®Œæ•´çš„checkpoint
        checkpoint_path = os.path.join(self.train_epoch_dir, f'checkpoint_epoch_{self.start_epoch}to{self.epochs}.pth')
        if os.path.isfile(checkpoint_path):
            try:
                # åœ¨GPUä¸ŠåŠ è½½checkpoint
                map_location = {'cuda:%d' % 0: 'cuda:%d' % self.local_rank} if self.is_distributed else None
                checkpoint = torch.load(checkpoint_path, map_location=map_location)
                
                # è·å–å®é™…çš„æ¨¡å‹ï¼ˆå‰¥ç¦»DDPåŒ…è£…ï¼‰
                generator_model = self.generator.module if self.is_distributed else self.generator
                discriminator_model = self.discriminator.module if self.is_distributed else self.discriminator
                
                generator_model.load_state_dict(checkpoint['generator_state_dict'])
                discriminator_model.load_state_dict(checkpoint['discriminator_state_dict'])
                self.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])
                self.optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])
                self.scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])
                self.scheduler_D.load_state_dict(checkpoint['scheduler_D_state_dict'])
                
                recovered_epoch = checkpoint['epoch']
                if is_main_process() and self.logger:
                    self.logger.info(f"{safe_emoji('âœ…', '[SUCCESS]')} æˆåŠŸä»checkpointæ¢å¤è®­ç»ƒçŠ¶æ€ï¼Œä¸Šæ¬¡è®­ç»ƒåˆ°ç¬¬{recovered_epoch}ä¸ªepoch")
                    self.logger.debug("ç”Ÿæˆå™¨ç»“æ„ï¼š\n%s", generator_model)
                    self.logger.debug("åˆ¤åˆ«å™¨ç»“æ„ï¼š\n%s", discriminator_model)
                    self.logger.debug("ç”Ÿæˆå™¨å‚æ•°æ•°é‡ï¼š %s", sum(p.numel() for p in generator_model.parameters()))
                    self.logger.debug("åˆ¤åˆ«å™¨å‚æ•°æ•°é‡ï¼š %s", sum(p.numel() for p in discriminator_model.parameters()))
                
                # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
                if self.is_distributed:
                    dist.barrier()
                
                return recovered_epoch + 1  # è¿”å›ä¸‹ä¸€ä¸ªè¦è®­ç»ƒçš„epoch
                
            except Exception as e:
                if is_main_process() and self.logger:
                    self.logger.warning(f"{safe_emoji('âš ï¸', '[WARNING]')} CheckpointåŠ è½½å¤±è´¥ï¼š{e}")
        
        # ä¼˜å…ˆçº§2: å°è¯•åŠ è½½ç®€å•çš„æ¨¡å‹æ–‡ä»¶
        generator_path = f'generator_simple_epoch_{self.start_epoch}to{self.epochs}.pth'
        discriminator_path = f'discriminator_simple_epoch_{self.start_epoch}to{self.epochs}.pth'
        
        if os.path.isfile(generator_path) and os.path.isfile(discriminator_path):
            try:
                map_location = {'cuda:%d' % 0: 'cuda:%d' % self.local_rank} if self.is_distributed else None
                
                # è·å–å®é™…çš„æ¨¡å‹ï¼ˆå‰¥ç¦»DDPåŒ…è£…ï¼‰
                generator_model = self.generator.module if self.is_distributed else self.generator
                discriminator_model = self.discriminator.module if self.is_distributed else self.discriminator
                
                generator_model.load_state_dict(torch.load(generator_path, map_location=map_location))
                discriminator_model.load_state_dict(torch.load(discriminator_path, map_location=map_location))
                
                if is_main_process() and self.logger:
                    self.logger.info(f"{safe_emoji('âœ…', '[SUCCESS]')} æˆåŠŸåŠ è½½ç®€å•æ¨¡å‹æ–‡ä»¶ï¼Œä»ç¬¬{self.start_epoch}ä¸ªepochå¼€å§‹è®­ç»ƒ")
                    self.logger.debug("ç”Ÿæˆå™¨ç»“æ„ï¼š\n%s", generator_model)
                    self.logger.debug("åˆ¤åˆ«å™¨ç»“æ„ï¼š\n%s", discriminator_model)
                
                # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
                if self.is_distributed:
                    dist.barrier()
                
                return self.start_epoch
                
            except Exception as e:
                if is_main_process() and self.logger:
                    self.logger.warning(f"{safe_emoji('âš ï¸', '[WARNING]')} ç®€å•æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        
        # ä¼˜å…ˆçº§3: å¯»æ‰¾å…¶ä»–å¯ç”¨çš„checkpointæ–‡ä»¶
        checkpoint_pattern = os.path.join(self.train_epoch_dir, 'checkpoint_epoch_*.pth')
        import glob
        checkpoint_files = glob.glob(checkpoint_pattern)
        if checkpoint_files:
            # é€‰æ‹©æœ€æ–°çš„checkpointæ–‡ä»¶
            latest_checkpoint = max(checkpoint_files, key=os.path.getctime)
            try:
                map_location = {'cuda:%d' % 0: 'cuda:%d' % self.local_rank} if self.is_distributed else None
                checkpoint = torch.load(latest_checkpoint, map_location=map_location)
                
                # è·å–å®é™…çš„æ¨¡å‹ï¼ˆå‰¥ç¦»DDPåŒ…è£…ï¼‰
                generator_model = self.generator.module if self.is_distributed else self.generator
                discriminator_model = self.discriminator.module if self.is_distributed else self.discriminator
                
                generator_model.load_state_dict(checkpoint['generator_state_dict'])
                discriminator_model.load_state_dict(checkpoint['discriminator_state_dict'])
                self.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])
                self.optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])
                self.scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])
                self.scheduler_D.load_state_dict(checkpoint['scheduler_D_state_dict'])
                
                recovered_epoch = checkpoint['epoch']
                if is_main_process() and self.logger:
                    self.logger.info(f"{safe_emoji('âœ…', '[SUCCESS]')} æ‰¾åˆ°å¹¶åŠ è½½äº†å…¶ä»–checkpointæ–‡ä»¶ï¼š{os.path.basename(latest_checkpoint)}")
                    self.logger.info(f"æ¢å¤åˆ°ç¬¬{recovered_epoch}ä¸ªepoch")
                
                # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
                if self.is_distributed:
                    dist.barrier()
                
                return recovered_epoch + 1
                
            except Exception as e:
                if is_main_process() and self.logger:
                    self.logger.warning(f"{safe_emoji('âš ï¸', '[WARNING]')} å…¶ä»–checkpointåŠ è½½å¤±è´¥ï¼š{e}")
        
        # æ‰€æœ‰åŠ è½½æ–¹å¼éƒ½å¤±è´¥
        if is_main_process() and self.logger:
            self.logger.info(f"{safe_emoji('â„¹ï¸', '[INFO]')} æœªæ‰¾åˆ°å¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
        
        # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
        if self.is_distributed:
            dist.barrier()
        
        return 0

    def save_state(self, epoch):
        """ä¿å­˜è®­ç»ƒçŠ¶æ€ï¼Œæ”¯æŒDDPæ¨¡å‹"""
        # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œå…ˆåŒæ­¥æ‰€æœ‰è¿›ç¨‹
        if self.is_distributed:
            dist.barrier()
        
        if not is_main_process():
            return
            
        checkpoint_path = os.path.join(self.train_epoch_dir, f'checkpoint_epoch_{self.start_epoch}to{self.epochs}.pth')
        
        # è·å–å®é™…çš„æ¨¡å‹çŠ¶æ€ï¼ˆå‰¥ç¦»DDPåŒ…è£…ï¼‰
        generator_state = self.generator.module.state_dict() if self.is_distributed else self.generator.state_dict()
        discriminator_state = self.discriminator.module.state_dict() if self.is_distributed else self.discriminator.state_dict()
        
        torch.save({
            'epoch': epoch,
            'generator_state_dict': generator_state,
            'discriminator_state_dict': discriminator_state,
            'optimizer_G_state_dict': self.optimizer_G.state_dict(),
            'optimizer_D_state_dict': self.optimizer_D.state_dict(),
            'scheduler_G_state_dict': self.scheduler_G.state_dict(),
            'scheduler_D_state_dict': self.scheduler_D.state_dict(),
        }, checkpoint_path)

    def load_state(self):
        # è¿™ä¸ªæ–¹æ³•ç°åœ¨å·²ç»è¢«_load_models_unifiedæ›¿ä»£ï¼Œä¿ç•™æ˜¯ä¸ºäº†å…¼å®¹æ€§
        checkpoint_path = os.path.join(self.train_epoch_dir, f'checkpoint_epoch_{self.start_epoch}to{self.epochs}.pth')
        if os.path.isfile(checkpoint_path):
            checkpoint = torch.load(checkpoint_path)
            self.generator.load_state_dict(checkpoint['generator_state_dict'])
            self.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
            self.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])
            self.optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])
            self.scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])
            self.scheduler_D.load_state_dict(checkpoint['scheduler_D_state_dict'])
            return checkpoint['epoch']
        else:
            return None

    def load_dataset(self):
        transform = transforms.Compose([
            transforms.Resize(self.image_size),
            transforms.CenterCrop(self.image_size),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ])

        dataset = MyDataset(root_dir=self.dataset_path, transform=transform)
        return dataset

    def split_dataset(self):
        """æ•°æ®é›†åˆ†å‰²ï¼Œæ”¯æŒåˆ†å¸ƒå¼é‡‡æ ·"""
        train_size = int(0.8 * len(self.dataset))
        val_size = len(self.dataset) - train_size
        train_dataset, val_dataset = random_split(self.dataset, [train_size, val_size])
        
        if self.is_distributed:
            # åˆ†å¸ƒå¼é‡‡æ ·å™¨
            train_sampler = DistributedSampler(
                train_dataset, 
                num_replicas=self.world_size, 
                rank=self.rank,
                shuffle=True
            )
            val_sampler = DistributedSampler(
                val_dataset,
                num_replicas=self.world_size,
                rank=self.rank,
                shuffle=False
            )
            
            train_dataloader = DataLoader(
                train_dataset, 
                batch_size=self.batch_size, 
                sampler=train_sampler,
                num_workers=0,
                collate_fn=collate_fn,
                pin_memory=True
            )
            val_dataloader = DataLoader(
                val_dataset, 
                batch_size=self.batch_size, 
                sampler=val_sampler,
                num_workers=0,
                collate_fn=collate_fn,
                pin_memory=True
            )
        else:
            # éåˆ†å¸ƒå¼è®­ç»ƒ
            train_dataloader = DataLoader(
                train_dataset, 
                batch_size=self.batch_size, 
                shuffle=True, 
                num_workers=0,
                collate_fn=collate_fn
            )
            val_dataloader = DataLoader(
                val_dataset, 
                batch_size=self.batch_size, 
                shuffle=False, 
                num_workers=0,
                collate_fn=collate_fn
            )
        
        return train_dataloader, val_dataloader

    def visualize_model_output(self, num_images=5):
        self.generator.eval()
        with torch.no_grad():
            z = torch.randn(num_images, self.latent_dim, 1, 1).to(self.device)
            fake_images = self.generator(z)
            fake_images = fake_images.cpu().detach()
            fig, axs = plt.subplots(1, num_images, figsize=(num_images * 3, 3))
            for i, img in enumerate(fake_images):
                axs[i].imshow(img.permute(1, 2, 0))
                axs[i].axis('off')
            plt.show()
            plt.close()

    def visualize_weights(self):
        for name, param in self.generator.named_parameters():
            if 'weight' in name:
                plt.figure(figsize=(15, 5))
                plt.title(f'{name} weights')
                plt.hist(param.data.cpu().numpy().flatten(), bins=100)
                plt.show()
                plt.close()

        for name, param in self.discriminator.named_parameters():
            if 'weight' in name:
                plt.figure(figsize=(15, 5))
                plt.title(f'{name} weights')
                plt.hist(param.data.cpu().numpy().flatten(), bins=100)
                plt.show()
                plt.close()

    def train(self):

        start_time = time.time()
        if is_main_process() and self.logger:
            self.logger.debug(f'{safe_emoji("ğŸš€", "[START]")} å¼€å§‹è®­ç»ƒçš„æ—¶é—´ä¸ºï¼š{time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())}')

        # åˆ›å»ºå­˜å‚¨ç”Ÿæˆå›¾ç‰‡çš„ç›®å½•ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if is_main_process() and not os.path.exists(os.path.join(self.train_epoch_dir, 'fake_images_new')):
            os.makedirs(os.path.join(self.train_epoch_dir, 'fake_images_new'))

        real_label = 1.0
        fake_label = 0.0
        fixed_noise = torch.randn(64, self.latent_dim, 1, 1, device=self.device)
        img_list = []
        G_losses = []
        D_losses = []
        iters = 0
        early_stopping_counter = 0

        if is_main_process() and self.logger:
            self.logger.debug(f'{safe_emoji("ğŸ”¥", "")}{"<" * 30}å¼€å§‹è®­ç»ƒ{">" * 30}{safe_emoji("ğŸ”¥", "")}')
        
        self.generator.train()
        self.discriminator.train()
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹åŠ è½½æ–¹æ³•
        start_epoch = self._load_models_unified()
        self.start_epoch = start_epoch
        
        # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­è®¾ç½®epochï¼ˆç”¨äºDistributedSamplerï¼‰
        if self.is_distributed and hasattr(self.train_dataloader.sampler, 'set_epoch'):
            self.train_dataloader.sampler.set_epoch(start_epoch)
        
        try:
            for epoch in range(start_epoch, self.epochs):
                # ä¸ºåˆ†å¸ƒå¼é‡‡æ ·å™¨è®¾ç½®epoch
                if self.is_distributed and hasattr(self.train_dataloader.sampler, 'set_epoch'):
                    self.train_dataloader.sampler.set_epoch(epoch)
                
                for i, data in enumerate(self.train_dataloader, 0):
                    real_cpu = data[0].to(self.device)
                    b_size = real_cpu.size(0)
                    
                    ############################
                    # (1) è®­ç»ƒåˆ¤åˆ«å™¨ï¼šæœ€å¤§åŒ– log(D(x)) + log(1 - D(G(z)))
                    ###########################
                    # åœ¨æ¢¯åº¦ç´¯ç§¯å¼€å§‹æ—¶æ¸…é›¶æ¢¯åº¦
                    if i % self.gradient_accumulation_steps == 0:
                        self.discriminator.zero_grad()
                    
                    # è®­ç»ƒçœŸå®æ•°æ®
                    label = torch.full((b_size,), real_label, dtype=torch.float, device=self.device)
                    
                    with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):
                        output = self.discriminator(real_cpu).view(-1)
                        errD_real = self.criterion(output, label)
                    
                    # æ··åˆç²¾åº¦è®­ç»ƒçš„æ­£ç¡®æµç¨‹
                    self.scaler.scale(errD_real).backward()
                    D_x = output.mean().item()

                    # è®­ç»ƒç”Ÿæˆçš„å‡æ•°æ®
                    noise = torch.randn(b_size, self.latent_dim, 1, 1, device=self.device)
                    with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):
                        fake = self.generator(noise)
                        label.fill_(fake_label)
                        output = self.discriminator(fake.detach()).view(-1)
                        errD_fake = self.criterion(output, label)
                    
                    self.scaler.scale(errD_fake).backward()
                    D_G_z1 = output.mean().item()
                    errD = errD_real + errD_fake
                    
                    # æ¢¯åº¦ç´¯ç§¯å¤„ç† - åœ¨ç´¯ç§¯æ­¥æ•°å®Œæˆæ—¶æ›´æ–°å‚æ•°
                    if (i + 1) % self.gradient_accumulation_steps == 0:
                        self.scaler.step(self.optimizer_D)
                        self.scaler.update()

                    ############################
                    # (2) è®­ç»ƒç”Ÿæˆå™¨ï¼šæœ€å¤§åŒ– log(D(G(z)))
                    ###########################
                    # åœ¨æ¢¯åº¦ç´¯ç§¯å¼€å§‹æ—¶æ¸…é›¶æ¢¯åº¦
                    if i % self.gradient_accumulation_steps == 0:
                        self.generator.zero_grad()
                    
                    label.fill_(real_label)  # ç”Ÿæˆå™¨å¸Œæœ›åˆ¤åˆ«å™¨è®¤ä¸ºå‡æ•°æ®æ˜¯çœŸçš„
                    
                    with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):
                        output = self.discriminator(fake).view(-1)
                        errG = self.criterion(output, label)
                    
                    self.scaler.scale(errG).backward()
                    D_G_z2 = output.mean().item()

                    # æ¢¯åº¦ç´¯ç§¯å¤„ç† - åœ¨ç´¯ç§¯æ­¥æ•°å®Œæˆæ—¶æ›´æ–°å‚æ•°
                    if (i + 1) % self.gradient_accumulation_steps == 0:
                        self.scaler.step(self.optimizer_G)
                        self.scaler.update()

                    # åªåœ¨ä¸»è¿›ç¨‹è®°å½•æ—¥å¿—
                    if i % 50 == 0 and is_main_process() and self.logger:
                        self.logger.debug('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                                     % (epoch, self.epochs, i, len(self.train_dataloader),
                                        errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

                    # åœ¨ä¸»è¿›ç¨‹ä¸­è®°å½•æŸå¤±
                    if is_main_process():
                        G_losses.append(errG.item())
                        D_losses.append(errD.item())

                    if ((iters % 500 == 0) or ((epoch == self.epochs - 1) and (i == len(self.train_dataloader) - 1))) and is_main_process():
                        with torch.no_grad():
                            fake = self.generator(fixed_noise.to(torch.float32)).detach().cpu()
                        img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

                    iters += 1

                # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
                if self.is_distributed:
                    dist.barrier()

                #åœ¨è®­ç»ƒå¾ªç¯ä¸­ï¼Œæ¯ä¸ªepochç»“æŸæ—¶ï¼Œè°ƒç”¨save_stateæ–¹æ³•æ¥ä¿å­˜çŠ¶æ€ï¼š
                self.save_state(epoch)

                # åœ¨æ¯ä¸ªepochç»“æŸæ—¶ä¿å­˜ç”Ÿæˆçš„å›¾åƒï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
                if is_main_process():
                    with torch.no_grad():
                        fake = self.generator(fixed_noise).detach().cpu()
                    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))
                    save_image(fake.data,os.path.join(self.train_epoch_dir, f'fake_images_new/fake_images_epoch_{epoch}_Loss_D_{errD.item():.4f}_Loss_G_{errG.item():.4f}_D_x_{D_x}_D_x_{(D_G_z1/D_G_z2):.4f}.png'), normalize=True)

                # åœ¨è®­ç»ƒå¾ªç¯ç»“æŸåï¼Œæ·»åŠ ä»¥ä¸‹ä»£ç ä»¥æ‰“å°ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„æŸå¤±å¹¶å¯è§†åŒ–ç”Ÿæˆçš„å›¾åƒ
                self.generator.eval()
                self.discriminator.eval()

                if epoch % 50==0 and is_main_process():
                    # å°†ç”Ÿæˆçš„å›¾åƒæ˜¾ç¤ºåœ¨æ§åˆ¶å°
                    plt.imshow(np.transpose(vutils.make_grid(fake, padding=2, normalize=True).cpu(), (1, 2, 0)))
                    plt.axis('off')
                    #plt.show()

                    # ç»˜åˆ¶ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„æŸå¤±æ›²çº¿
                    plt.figure(figsize=(10, 5))
                    plt.title(f"Generator and Discriminator Loss After Epoch {epoch}")
                    plt.plot(G_losses, label="Generator Loss")
                    plt.plot(D_losses, label="Discriminator Loss")
                    plt.xlabel("Iterations")
                    plt.ylabel("Loss")
                    plt.legend()
                    #plt.show()

                # ä¿®æ­£éªŒè¯é€»è¾‘ï¼šä½¿ç”¨validation_frequencyè€Œä¸æ˜¯patienceä½œä¸ºéªŒè¯é¢‘ç‡
                if epoch % self.validation_frequency == 0:
                    self.generator.eval()
                    val_loss = 0
                    with torch.no_grad():
                        for val_i, val_data in enumerate(self.val_dataloader, 0):
                            real_cpu = val_data[0].to(self.device)
                            b_size = real_cpu.size(0)
                            label = torch.full((b_size,), real_label, dtype=torch.float, device=self.device)
                            output = self.discriminator(real_cpu).view(-1)
                            errD_real = self.criterion(output, label)

                            noise = torch.randn(b_size, self.latent_dim, 1, 1, device=self.device)
                            fake = self.generator(noise)
                            label.fill_(fake_label)
                            output = self.discriminator(fake.detach()).view(-1)
                            errD_fake = self.criterion(output, label)
                            errD = errD_real + errD_fake

                            label.fill_(real_label)
                            output = self.discriminator(fake).view(-1)
                            errG = self.criterion(output, label)

                            val_loss += errG.item() + errD.item()

                    val_loss /= len(self.val_dataloader)
                    
                    # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­åŒæ­¥éªŒè¯æŸå¤±
                    if self.is_distributed:
                        val_loss_tensor = torch.tensor(val_loss, device=self.device)
                        dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.SUM)
                        val_loss = val_loss_tensor.item() / self.world_size
                    
                    if is_main_process() and self.logger:
                        self.logger.debug(f'è®­ç»ƒåˆ°ç¬¬{epoch}ä¸ªå‘¨æœŸåçš„éªŒè¯æŸå¤±ä¸º: {val_loss}')

                    # æ—©åœé€»è¾‘ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹åŒæ­¥
                    should_stop = False
                    if val_loss < self.best_val_loss - self.min_delta:
                        self.best_val_loss = val_loss
                        early_stopping_counter = 0
                        self.generator.train()
                        self.discriminator.train()

                        # åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜æ¨¡å‹
                        if is_main_process():
                            # è·å–å®é™…çš„æ¨¡å‹çŠ¶æ€ï¼ˆå‰¥ç¦»DDPåŒ…è£…ï¼‰
                            generator_state = self.generator.module.state_dict() if self.is_distributed else self.generator.state_dict()
                            discriminator_state = self.discriminator.module.state_dict() if self.is_distributed else self.discriminator.state_dict()
                            
                            torch.save({
                                'epoch': epoch,
                                'generator_state_dict': generator_state,
                                'optimizer_G_state_dict': self.optimizer_G.state_dict(),
                                'scheduler_G_state_dict': self.scheduler_G.state_dict(),
                                'best_val_loss': self.best_val_loss,
                                'val_loss': val_loss,
                                'early_stopping_counter': early_stopping_counter,
                            }, os.path.join(self.train_epoch_dir, f'generator_all_epoch_{start_epoch}to{self.epochs}.pth'))

                            torch.save({
                                'epoch': epoch,
                                'discriminator_state_dict': discriminator_state,
                                'optimizer_D_state_dict': self.optimizer_D.state_dict(),
                                'scheduler_D_state_dict': self.scheduler_D.state_dict(),
                                'best_val_loss': self.best_val_loss,
                                'val_loss': val_loss,
                                'early_stopping_counter': early_stopping_counter,
                            }, os.path.join(self.train_epoch_dir, f'discriminator_all_epoch_{start_epoch}to{self.epochs}.pth'))
                    else:
                        early_stopping_counter += 1
                        if is_main_process() and self.logger:
                            self.logger.debug(f'è®­ç»ƒåˆ°ç¬¬{epoch}ä¸ªå‘¨æœŸåæ—©åœæ¬¡æ•°+1ï¼Œå½“å‰æ—©åœæ¬¡æ•°ä¸ºï¼š{early_stopping_counter}.å› ä¸ºéªŒè¯æŸå¤±æ²¡æœ‰æ”¹å–„ï¼Œæˆ–è€…æ”¹å–„çš„å¹…åº¦å°äºmin_delta')
                        if early_stopping_counter >= self.patience:
                            should_stop = True
                    
                    # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­åŒæ­¥æ—©åœå†³å®šå’Œè®¡æ•°å™¨
                    if self.is_distributed:
                        # åŒæ­¥should_stop
                        should_stop_tensor = torch.tensor(int(should_stop), device=self.device)
                        dist.all_reduce(should_stop_tensor, op=dist.ReduceOp.MAX)
                        should_stop = bool(should_stop_tensor.item())
                        
                        # åŒæ­¥early_stopping_counter
                        counter_tensor = torch.tensor(early_stopping_counter, device=self.device)
                        dist.all_reduce(counter_tensor, op=dist.ReduceOp.MAX)
                        early_stopping_counter = counter_tensor.item()
                    
                    if should_stop:
                        if is_main_process() and self.logger:
                            self.logger.debug(f'è®­ç»ƒåˆ°ç¬¬{epoch}ä¸ªå‘¨æœŸååœæ­¢è®­ç»ƒï¼Œå› ä¸ºæ—©åœæ¬¡æ•°å¤§äºç­‰äºè€å¿ƒå€¼ï¼š{self.patience}ä¸”éªŒè¯æŸå¤±æ²¡æœ‰æ”¹å–„ï¼Œæˆ–è€…æ”¹å–„çš„å¹…åº¦å°äºmin_delta')
                        break

        except KeyboardInterrupt:
            if is_main_process() and self.logger:
                self.logger.info(f'\n{safe_emoji("ğŸ›‘", "[STOP]")} ç”¨æˆ·æ‰‹åŠ¨åœæ­¢è®­ç»ƒ (Epoch {epoch}) {safe_emoji("ğŸ›‘", "[STOP]")}')
                self.logger.info(f'{safe_emoji("ğŸ’¾", "[SAVE]")} æ­£åœ¨ä¿å­˜å½“å‰è®­ç»ƒçŠ¶æ€...')
            # ä¿å­˜å½“å‰çŠ¶æ€
            self.save_state(epoch)
            # ä¿å­˜ç®€å•æ¨¡å‹ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
            if is_main_process():
                generator_state = self.generator.module.state_dict() if self.is_distributed else self.generator.state_dict()
                discriminator_state = self.discriminator.module.state_dict() if self.is_distributed else self.discriminator.state_dict()
                torch.save(generator_state, os.path.join(self.train_epoch_dir,f'generator_simple_epoch_{start_epoch}to{epoch}_interrupted.pth'))
                torch.save(discriminator_state, os.path.join(self.train_epoch_dir,f'discriminator_simple_epoch_{start_epoch}to{epoch}_interrupted.pth'))
                self.logger.info(f'{safe_emoji("âœ…", "[SUCCESS]")} è®­ç»ƒçŠ¶æ€å·²ä¿å­˜ï¼å¯ä»¥é€šè¿‡è®¾ç½®start_epoch={epoch+1}æ¥æ¢å¤è®­ç»ƒ')
            return G_losses, D_losses, img_list

        if is_main_process() and self.logger:
            self.logger.debug(f'{safe_emoji("ğŸ‰", "[COMPLETE]")} è®­ç»ƒç»“æŸï¼')

        # ä¿å­˜æ¨¡å‹ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if is_main_process():
            generator_state = self.generator.module.state_dict() if self.is_distributed else self.generator.state_dict()
            discriminator_state = self.discriminator.module.state_dict() if self.is_distributed else self.discriminator.state_dict()
            torch.save(generator_state, os.path.join(self.train_epoch_dir,f'generator_simple_epoch_{start_epoch}to{self.epochs}.pth'))
            torch.save(discriminator_state, os.path.join(self.train_epoch_dir,f'discriminator_simple_epoch_{start_epoch}to{self.epochs}.pth'))

        # ç»˜åˆ¶æŸå¤±æ›²çº¿ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if is_main_process():
            plt.figure(figsize=(10, 5))
            plt.title(f"Generator and Discriminator Loss During Training Between {start_epoch}To{self.epochs} Epoch \nè®­ç»ƒæœŸé—´ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨æŸè€—")
            plt.plot(G_losses, label="Gç”Ÿæˆå™¨")
            plt.plot(D_losses, label="Dåˆ¤åˆ«å™¨")
            plt.xlabel("iterationsè¿­ä»£")
            plt.ylabel("LossæŸè€—")
            plt.legend()
            plt.show()

            # åŠ¨æ€å±•ç¤ºç”Ÿæˆå›¾ç‰‡çš„è¿‡ç¨‹
            # åœ¨åˆ›å»ºåŠ¨ç”»ä¹‹å‰è®¾ç½®embed_limit
            plt.rcParams['animation.embed_limit'] = 30.0  # æˆ–è€…è®¾ç½®é€‚åˆä½ éœ€æ±‚çš„å€¼

            fig = plt.figure(figsize=(8, 8))
            plt.axis("off")
            ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]
            ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
            HTML(ani.to_jshtml())

            #å¦å¤–ä¿å­˜ç”Ÿæˆå›¾ç‰‡çš„è¿‡ç¨‹åŠ¨ç”»ä¸ºhtmlæ–‡ä»¶

            '''
            å®ƒé¦–å…ˆä½¿ç”¨to_jshtmlæ–¹æ³•å°†åŠ¨ç”»è½¬æ¢ä¸ºä¸€ä¸ªHTMLå­—ç¬¦ä¸²ï¼Œç„¶åå°†è¿™ä¸ªå­—ç¬¦ä¸²å†™å…¥åˆ°ä¸€ä¸ªåä¸ºanimation.htmlçš„æ–‡ä»¶ä¸­ã€‚
            ä½ å¯ä»¥åœ¨ä»»ä½•æµè§ˆå™¨ä¸­æ‰“å¼€è¿™ä¸ªæ–‡ä»¶æ¥æŸ¥çœ‹åŠ¨ç”»ã€‚
            '''

            html = ani.to_jshtml()
            with open(os.path.join(self.train_epoch_dir,f'animation_epoch_{self.start_epoch}to{self.epochs}.html'), 'w') as f:
                f.write(html)

            # å¯è§†åŒ–æ¨¡å‹è¾“å‡º
            self.visualize_model_output()
            # å¯è§†åŒ–æƒé‡
            self.visualize_weights()

            self.logger.debug(f'{safe_emoji("ğŸ”¥", "")}{"<" * 30}è®­ç»ƒç»“æŸ{">" * 30}{safe_emoji("ğŸ”¥", "")}')

        # è®¡ç®—è€—æ—¶ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if is_main_process() and self.logger:
            end_time = time.time()
            self.logger.debug(f'{safe_emoji("ğŸ", "[END]")} ç»“æŸè®­ç»ƒçš„æ—¶é—´ä¸ºï¼š{time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())}')
            diff_time = end_time - start_time
            hours = int(diff_time // 3600)
            minutes = int((diff_time % 3600) // 60)
            seconds = int(diff_time % 60)
            self.logger.debug(f'{safe_emoji("â±ï¸", "[TIME]")} è®­ç»ƒæ€»è€—æ—¶ï¼š{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds}ç§’')
        return G_losses, D_losses, img_list


if __name__ == '__main__':
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='GANè®­ç»ƒå™¨ - æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ')
    parser.add_argument('--train_dir', type=str, default='./dataset', 
                       help='è®­ç»ƒæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--epochs', type=int, default=2000, 
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=1024, 
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=0.0002, 
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--lr_g', type=float, default=None, 
                       help='ç”Ÿæˆå™¨å­¦ä¹ ç‡ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨learning_rateï¼‰')
    parser.add_argument('--lr_d', type=float, default=None, 
                       help='åˆ¤åˆ«å™¨å­¦ä¹ ç‡ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨learning_rateï¼‰')
    parser.add_argument('--latent_dim', type=int, default=100, 
                       help='æ½œåœ¨ç©ºé—´ç»´åº¦')
    parser.add_argument('--image_size', type=int, default=64, 
                       help='å›¾åƒå¤§å°')
    parser.add_argument('--num_layers', type=int, default=4, 
                       help='ç½‘ç»œå±‚æ•°')
    parser.add_argument('--base_channels', type=int, default=64, 
                       help='åŸºç¡€é€šé“æ•°')
    parser.add_argument('--patience', type=int, default=500, 
                       help='æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--validation_frequency', type=int, default=10, 
                       help='éªŒè¯é¢‘ç‡ï¼ˆæ¯Nä¸ªepochéªŒè¯ä¸€æ¬¡ï¼‰')
    parser.add_argument('--load_models', action='store_true', 
                       help='æ˜¯å¦åŠ è½½é¢„è®­ç»ƒæ¨¡å‹')
    parser.add_argument('--start_epoch', type=int, default=0, 
                       help='èµ·å§‹è®­ç»ƒè½®æ•°')
    parser.add_argument('--gradient_accumulation_steps', type=int, default=1, 
                       help='æ¢¯åº¦ç´¯ç§¯æ­¥æ•°')
    
    args = parser.parse_args()
    
    # å¤„ç†å­¦ä¹ ç‡å‚æ•°
    lr_g = args.lr_g if args.lr_g is not None else args.learning_rate
    lr_d = args.lr_d if args.lr_d is not None else args.learning_rate
    
    # ä¹Ÿæ”¯æŒä»ç¯å¢ƒå˜é‡è·å–æ•°æ®é›†è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰
    dataset_path = os.getenv('DATASET_PATH', args.train_dir)
    
    # åœ¨ä¸»è¿›ç¨‹ä¸­æ‰“å°é…ç½®ä¿¡æ¯
    if is_main_process():
        print(f"ğŸš€ å¯åŠ¨GANè®­ç»ƒå™¨")
        print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset_path}")
        print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {args.epochs}")
        print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
        print(f"ğŸ“Š å­¦ä¹ ç‡ - ç”Ÿæˆå™¨: {lr_g}, åˆ¤åˆ«å™¨: {lr_d}")
        print(f"ğŸ–¼ï¸  å›¾åƒå°ºå¯¸: {args.image_size}x{args.image_size}")
        print(f"ğŸ—ï¸  ç½‘ç»œå±‚æ•°: {args.num_layers}, åŸºç¡€é€šé“æ•°: {args.base_channels}")
        print(f"â° æ—©åœè€å¿ƒå€¼: {args.patience}, éªŒè¯é¢‘ç‡: {args.validation_frequency}")
        print(f"ğŸ”„ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {args.load_models}")
        if args.start_epoch > 0:
            print(f"â–¶ï¸  ä»ç¬¬ {args.start_epoch} è½®å¼€å§‹è®­ç»ƒ")
    
    trainer = GANTrainer(
        dataset_path=dataset_path,
        latent_dim=args.latent_dim,
        lr_G=lr_g,
        lr_D=lr_d,
        batch_size=args.batch_size,
        image_size=args.image_size,
        epochs=args.epochs,
        start_epoch=args.start_epoch,
        patience=args.patience,
        num_layers=args.num_layers,
        base_channels=args.base_channels,
        load_models=args.load_models,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        validation_frequency=args.validation_frequency
    )
    
    try:
        trainer.train()
    except Exception as e:
        if is_main_process():
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise
    finally:
        # æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ
        cleanup_distributed()
        if is_main_process():
            print("ğŸ§¹ åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒå·²æ¸…ç†")
